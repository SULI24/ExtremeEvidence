# Configurations for pretrained checkpoint. Please do not modify it.
dataset:
  dataset_name: "sevir"
  img_height: 384
  img_width: 384
  in_len: 13
  out_len: 12
  seq_len: 25
  plot_stride: 2
  interval_real_time: 5
  sample_mode: "sequent"
  stride: 12
  layout: "NTHWC"
  start_date: null
  train_val_split_date: [2019, 1, 1]
  train_test_split_date: [2019, 6, 1]
  end_date: null
  metrics_mode: "0"
  metrics_list: ['csi', 'pod', 'sucr', 'bias']
  threshold_list: [16, 74, 133, 160, 181, 219]
layout:
  in_len: 13
  out_len: 12
  layout: "NTHWC"
optim:
  total_batch_size: 32
  micro_batch_size: 2
  seed: 0
  method: "adam"
  lr: 0.001
  wd: 0.0
  gradient_clip_val: 1.0
  max_epochs: 25
  # scheduler
  lr_scheduler_mode: "cosine"
  min_lr_ratio: 1.0e-3
  warmup_min_lr_ratio: 0.0
  warmup_percentage: 0.2
  # early stopping
  early_stop: true
  early_stop_mode: "min"
  early_stop_patience: 20
  save_top_k: 1
logging:
  logging_prefix: "UNet"
  monitor_lr: true
  monitor_device: false
  # track_grad_norm: -1
  use_wandb: true
trainer:
  check_val_every_n_epoch: 1
  log_step_ratio: 0.001
  precision: 32
vis:
  train_example_data_idx_list: [0, ]
  val_example_data_idx_list: [80, ]
  test_example_data_idx_list: [0, 80, 160, 240, 320, 400]
  eval_example_only: false
  plot_stride: 2
model:
  name: unet
  input_shape: [13, 384, 384, 1]
  target_shape: [12, 384, 384, 1]
  enc_nodes: [32, 64, 128, 256]
  center: 1024
  dec_nodes: [256, 128, 64, 32]
  activation: 'relu'
loss:
  loss_fn: 'mse'
  edl: False
  edl_act: 'relu'
  lambda: 1.0
  lambda_increasing: True
  slope: 0.1
  kl: False
  omega: 0.01